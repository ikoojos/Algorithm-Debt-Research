{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikoojos/Algorithm-Debt-Research/blob/master/SVM_Hash.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Add the shared module folder to Python's path\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/AD Final Experiments')\n",
        "import importlib\n",
        "import utils\n",
        "importlib.reload(utils)\n",
        "from utils import *\n",
        "from preprocessing import preprocess_data  # Import preprocess_data function\n",
        "from splitting import split_data  # Import split_data function\n",
        "\n",
        "print(\"Imports loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "SROlvyyO88QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979e791d-b9fd-46d6-f6c8-8a9b5d1caa8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Imports loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "zmOBRhOmSFTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "yOcI2rrTPBjo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "file_path = '/content/drive/My Drive/AD Identification using SATD/liu_datset_processed.csv'\n",
        "data = preprocess_data(file_path)  # Use preprocess_data to preprocess the dataset\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train_final, X_val, X_test, y_train_final, y_val, y_test = split_data(data)  # Use split_data to split data\n",
        "\n",
        "# Check if data splitting was successful\n",
        "print(f\"Training data shape: {X_train_final.shape}, Validation data shape: {X_val.shape}, Test data shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],  # Removed 'poly'\n",
        "    'gamma': ['scale', 'auto']   # Relevant for RBF kernel\n",
        "}\n",
        "\n",
        "# Initialise variables to track the best model\n",
        "best_score = -1\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "# Perform stratified 5-fold cross-validation on the training set\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for C, kernel, gamma in product(param_grid['C'], param_grid['kernel'], param_grid['gamma']):\n",
        "    fold_scores = []\n",
        "    for train_idx, val_idx in skf.split(X_train_final, y_train_final):\n",
        "        X_train_fold, X_val_fold = X_train_final.iloc[train_idx], X_train_final.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train_final.iloc[train_idx], y_train_final.iloc[val_idx]\n",
        "\n",
        "        try:\n",
        "            # Define the pipeline\n",
        "            pipeline = Pipeline([\n",
        "                ('Hash', HashingVectorizer()),  # CountVectorizer for feature extraction\n",
        "                ('scaler', StandardScaler(with_mean=False)),  # StandardScaler for scaling\n",
        "                ('clf', SVC(C=C, kernel=kernel, gamma=gamma, random_state=42, class_weight='balanced'))  # SVM model\n",
        "            ])\n",
        "\n",
        "            # Train on training fold\n",
        "            pipeline.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "            # Validate on validation fold\n",
        "            y_val_fold_pred = pipeline.predict(X_val_fold)\n",
        "            fold_score = accuracy_score(y_val_fold, y_val_fold_pred)\n",
        "            fold_scores.append(fold_score)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping configuration C={C}, kernel={kernel}, gamma={gamma} due to error: {e}\")\n",
        "\n",
        "    # Calculate average score across all folds\n",
        "    avg_fold_score = np.mean(fold_scores)\n",
        "    cv_scores.append(avg_fold_score)\n",
        "\n",
        "    # Update best parameters if current score is better\n",
        "    if avg_fold_score > best_score:\n",
        "        best_score = avg_fold_score\n",
        "        best_params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n",
        "        best_model = pipeline\n",
        "\n",
        "print(f\"Best parameters found with Stratified CV: {best_params}\")\n",
        "#print(f\"Best cross-validated accuracy on training set: {best_score}\")\n",
        "\n",
        "# Ensure best_model is not None\n",
        "if best_model is not None:\n",
        "    # Evaluate the best model on the validation set\n",
        "    y_val_pred = best_model.predict(X_val)\n",
        "    val_score = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"Validation set accuracy: {val_score}\")\n",
        "\n",
        "    # Evaluate the best model on the test set\n",
        "    y_test_pred = best_model.predict(X_test)\n",
        "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "    classification_rep_test = classification_report(y_test, y_test_pred)\n",
        "\n",
        "    print(\"\\nTest Confusion Matrix:\")\n",
        "    print(conf_matrix_test)\n",
        "    print(\"\\nTest Classification Report:\")\n",
        "    print(classification_rep_test)\n",
        "else:\n",
        "    print(\"No valid model found during grid search.\")\n"
      ],
      "metadata": {
        "id": "6ul4ifv36vE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef82d5d4-a6e9-43e8-f804-aecad399c795"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (24879,), Validation data shape: (6220,), Test data shape: (7775,)\n",
            "Best parameters found with Stratified CV: {'C': 0.01, 'kernel': 'linear', 'gamma': 'scale'}\n",
            "Validation set accuracy: 0.8390675241157556\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[  75    0    2   72    0    5    0   46]\n",
            " [   1   31    7   30    0    4    1   15]\n",
            " [   2    1   50   55    0    6    3   18]\n",
            " [  39   11   46 1754    2  108   10  236]\n",
            " [   1    0    0    8    7    3    0    4]\n",
            " [   7    3    9  120    0  218    3   27]\n",
            " [   1    0    6   44    1    9   57   25]\n",
            " [  26    4   15  169    4   14    5 4355]]\n",
            "\n",
            "Test Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "             ALGORITHM       0.49      0.38      0.43       200\n",
            "         COMPATIBILITY       0.62      0.35      0.45        89\n",
            "                DEFECT       0.37      0.37      0.37       135\n",
            "                DESIGN       0.78      0.80      0.79      2206\n",
            "         DOCUMENTATION       0.50      0.30      0.38        23\n",
            "        IMPLEMENTATION       0.59      0.56      0.58       387\n",
            "                  TEST       0.72      0.40      0.51       143\n",
            "WITHOUT_CLASSIFICATION       0.92      0.95      0.93      4592\n",
            "\n",
            "              accuracy                           0.84      7775\n",
            "             macro avg       0.62      0.51      0.55      7775\n",
            "          weighted avg       0.84      0.84      0.84      7775\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}