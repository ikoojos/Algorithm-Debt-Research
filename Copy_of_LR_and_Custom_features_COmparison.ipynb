{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikoojos/Algorithm-Debt-Research/blob/master/Copy_of_LR_and_Custom_features_COmparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMA9H5i62C9Z",
        "outputId": "177e98bf-134f-4af4-ebd4-dbe13f263649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/AD Final Experiments\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/AD Final Experiments'\n",
        "\n",
        "# General imports\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "import importlib\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Custom modules\n",
        "sys.path.append('/content/drive/My Drive/AD Final Experiments')\n",
        "from preprocessing import preprocess_data\n",
        "from splitting import split_data\n",
        "from utils import *\n",
        "from evaluate_model import evaluate_best_model\n",
        "from lr_tuning import hyperparameter_tuning\n",
        "\n",
        "# Reload custom modules to ensure latest updates\n",
        "for module in ['preprocessing', 'splitting', 'utils', 'evaluate_model', 'lr_tuning']:\n",
        "    importlib.reload(sys.modules[module])\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/AD Identification using SATD/liu_datset_processed.csv'\n",
        "data = preprocess_data(file_path)\n",
        "#X_train_final, X_val, X_test, y_train_final, y_val, y_test = split_data(data)\n",
        "\n",
        "print(\"Data preprocessing Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVCpI8UyHaMr",
        "outputId": "6d263c6e-1769-4aab-d821-0c4c1e49fc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data\n",
        "X = df['Comments'].apply(lambda x: x.lower().strip())\n",
        "y = df['TDType']\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "class CustomFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, keywords, save_csv=False, csv_path=None):\n",
        "        self.keywords = keywords\n",
        "        self.save_csv = save_csv\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # Extract custom features\n",
        "        custom_features = [\n",
        "            {f'contains_{kw}': int(kw in text.lower()) for kw in self.keywords}\n",
        "            for text in X\n",
        "        ]\n",
        "\n",
        "\n",
        "        custom_features_df = pd.DataFrame(custom_features)\n",
        "\n",
        "        if self.save_csv and self.csv_path:\n",
        "            combined_df = pd.DataFrame({'Comments': X}).reset_index(drop=True)\n",
        "            combined_df = pd.concat([combined_df, custom_features_df], axis=1)\n",
        "\n",
        "            if y is not None:\n",
        "                combined_df['TDType'] = y.reset_index(drop=True) if isinstance(y, pd.Series) else pd.Series(y).reset_index(drop=True)\n",
        "\n",
        "            combined_df.to_csv(self.csv_path, index=False)\n",
        "            print(f\"CSV saved to {self.csv_path}\")\n",
        "\n",
        "        # Return sparse matrix of features for the pipeline\n",
        "        return csr_matrix(custom_features_df.values)\n",
        "\n",
        "keywords = ['shape', 'input', 'tensor', 'output', 'size', 'convolution',\n",
        "            'value', 'efficient', 'matrix', 'model', 'node', 'function', 'batch']\n",
        "\n",
        "# Save CSVs\n",
        "debug_extractor = CustomFeatureExtractor(keywords, save_csv=True, csv_path=\"Custom AD Features.csv\")\n",
        "debug_extractor.transform(X_train_raw, y_train)\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('vectorizer', CountVectorizer()),\n",
        "        ('custom', CustomFeatureExtractor(keywords, save_csv=False))  # Disable saving in pipeline\n",
        "    ])),\n",
        "    ('clf', LogisticRegression(class_weight='balanced', random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'clf__C': [0.01, 1, 10],\n",
        "    'clf__penalty': ['l2'],\n",
        "    'clf__max_iter': [100, 200]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train_raw, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(f\"Best F1 Score (Macro) on Training Set: {best_score:.2f}\")\n",
        "\n",
        "y_pred_test = best_model.predict(X_test_raw)\n",
        "\n",
        "print(\"\\nEvaluation on Test Set:\")\n",
        "print(f\"F1 Score (Macro): {f1_score(y_test, y_pred_test, average='macro'):.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WcU8GgLondV",
        "outputId": "b0a9a012-4a31-44fc-9934-4c058deaaa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved to Custom AD Features.csv\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Best Parameters: {'clf__C': 10, 'clf__max_iter': 100, 'clf__penalty': 'l2'}\n",
            "Best F1 Score (Macro) on Training Set: 0.66\n",
            "\n",
            "Evaluation on Test Set:\n",
            "F1 Score (Macro): 0.68\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "             ALGORITHM       0.51      0.57      0.54       200\n",
            "         COMPATIBILITY       0.56      0.55      0.55        89\n",
            "                DEFECT       0.50      0.59      0.54       135\n",
            "                DESIGN       0.86      0.82      0.84      2206\n",
            "         DOCUMENTATION       0.62      0.57      0.59        23\n",
            "        IMPLEMENTATION       0.63      0.75      0.68       387\n",
            "                  TEST       0.70      0.76      0.73       143\n",
            "WITHOUT_CLASSIFICATION       0.97      0.96      0.96      4592\n",
            "\n",
            "              accuracy                           0.88      7775\n",
            "             macro avg       0.67      0.70      0.68      7775\n",
            "          weighted avg       0.89      0.88      0.88      7775\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 114    2    3   49    0    7    2   23]\n",
            " [   2   49    3   14    0    9    4    8]\n",
            " [   5    3   79   28    0    4    5   11]\n",
            " [  68   26   50 1801    5  138   19   99]\n",
            " [   3    0    0    4   13    2    1    0]\n",
            " [   3    1   12   67    0  292    6    6]\n",
            " [   0    1    2   14    1    7  109    9]\n",
            " [  30    6    9  122    2    7    9 4407]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(best_model, 'LR_CustomFeatures.pkl')\n",
        "\n",
        "# Later, load it without retraining\n",
        "best_model = joblib.load('LR_CustomFeatures.pkl')\n"
      ],
      "metadata": {
        "id": "X4siFTIm7ms5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm_examples = [\n",
        "    \"Adjust learning per minibatches at very beginning of training process this could be used to tackle the unstableness of ASGD\",\n",
        "    \"TODO: We should be able to move instead of copy but it currently isn't strightforward due to redU and redVT being slices\",\n",
        "\n",
        "    \"Hack for the tracer that allows us to represent RNNs as singlenodes and export them to ONNX in this form\",\n",
        "\n",
        "    \"Linux gcc barfs on this ^^ for 'us = (double)((std::wstring)arg).size();' due to some ambiguity error (while it works fine with Visual Studio). If you encounter this, instead say 'us = (double)((const std::wstring&)arg).size();' with a &. Don't forget the const (I have seen broken typecasts without).\",\n",
        "    \"TODO: fix libname for OSX / Windows\",\n",
        "    \"TODO: just load 5.1, not 5.1.3TODO: dynamic version checks via cudnnGetVersion\",\n",
        "    \"/* TODO: remove the extra copies of the input. These are only * used for debugging purposes during development and testing. */\",\n",
        "    \"/*TODO: merge with call site*/ void BackpropToLeftS(Matrix<ElemType & input1FunctionValues, Matrix<ElemType & input0GradientValues, const Matrix<ElemType & gradientValues, Matrix<ElemType & tempMatrix) { tempMatrix.SetValue(gradientValues); tempMatrix.ColumnElementMultiplyWith(input1FunctionValues); input0GradientValues += tempMatrix;\",\n",
        "    \"TODO vectorize mixed product\",\n",
        "\n",
        "    \"TODO(b/73448937): Move all update damping code to a separate class/function.\",\n",
        "    \"This really should be done in an external debugging tool\",\n",
        "    \"======================================================================= ReshapeNode -- reshape input matrix TODO: Why is this in NonlinearityNodes.h? Should he linear algebra no? =======================================================================\",\n",
        "\n",
        "\n",
        "    \"TODO(nsilberman): Documentation.\",\n",
        "    \"todo: add assertion }\",\n",
        "    \"TODO: add loading from checkpoint\",\n",
        "    \"TODO(satok): Implement all possible cases.\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Optional: convert to lowercase and strip whitespace, same as training\n",
        "llm_examples_clean = [c.lower().strip() for c in llm_examples]\n"
      ],
      "metadata": {
        "id": "F0vYG7XVpFhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on LLM examples\n",
        "llm_predictions = best_model.predict(llm_examples_clean)\n",
        "\n",
        "# Print results\n",
        "for comment, pred in zip(llm_examples, llm_predictions):\n",
        "    print(f\"Comment: {comment}\\nYour Model Prediction: {pred}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHvHxWwxttQH",
        "outputId": "6a0bbc64-e454-489e-975e-10b16b34563e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment: Adjust learning per minibatches at very beginning of training process this could be used to tackle the unstableness of ASGD\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: FIXME NEON has 16 quad registers, but since the current register allocator is so bad, it is much better to reduce it to 8\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: We keep track of the pending count and dead input count for each graph node. The representation used here is designed to be cache efficient for graphs with large numbers of nodes, where most nodes have relatively small maximum pending counts (e.g. for one LSTM model, 99% of 5000+ nodes had in-degrees of 3 or less). We use one byte to hold both the pending and dead count for a node where these together can fit in one byte, and we use a hash table to handle the rare node ids that need larger counts than this. TODO(yuanbyu): We current use O(# of nodes in partition) space even for nested iterations where only a small fraction of the nodes are involved. This is not efficient if the subgraph for the frame is only a small subset of the partition. We should make the vector size to be only the size of the frame subgraph.\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: TODO: We should be able to move instead of copy but it currently isn't strightforward due to redU and redVT being slices\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: note: the temp variable here gets completely eliminated by optimization\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: Hack for the tracer that allows us to represent RNNs as singlenodes and export them to ONNX in this form\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: TODO we could do this much more efficiently, with buffer re-use, etc.\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: #pragma omp parallel for TODO: Depending in circumstance, it may be more efficient to parallelize over rows.\n",
            "Your Model Prediction: ALGORITHM\n",
            "\n",
            "Comment: Linux gcc barfs on this ^^ for 'us = (double)((std::wstring)arg).size();' due to some ambiguity error (while it works fine with Visual Studio). If you encounter this, instead say 'us = (double)((const std::wstring&)arg).size();' with a &. Don't forget the const (I have seen broken typecasts without).\n",
            "Your Model Prediction: COMPATIBILITY\n",
            "\n",
            "Comment: TODO: fix libname for OSX / WindowsTODO: just load 5.1, not 5.1.3TODO: dynamic version checks via cudnnGetVersion\n",
            "Your Model Prediction: COMPATIBILITY\n",
            "\n",
            "Comment: /* TODO: remove the extra copies of the input. These are only * used for debugging purposes during development and testing. */\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: /*TODO: merge with call site*/ void BackpropToLeftS(Matrix<ElemType & input1FunctionValues, Matrix<ElemType & input0GradientValues, const Matrix<ElemType & gradientValues, Matrix<ElemType & tempMatrix) { tempMatrix.SetValue(gradientValues); tempMatrix.ColumnElementMultiplyWith(input1FunctionValues); input0GradientValues += tempMatrix;\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: TODO vectorize mixed product\n",
            "Your Model Prediction: IMPLEMENTATION\n",
            "\n",
            "Comment: TODO: if p2p isn't supported, this should become HOST-only allocation\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: TODO(b/73448937): Move all update damping code to a separate class/function.\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: This really should be done in an external debugging tool\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: ======================================================================= ReshapeNode -- reshape input matrix TODO: Why is this in NonlinearityNodes.h? Should he linear algebra no? =======================================================================\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: TODO(xpan): Make it text proto if it doesn't scale.Each line of the manifest file specifies an entry. The entry can be1) TestNameRegex // E.g. CumprodTest.* Or2) TestName TypeName // E.g. AdamOptimizerTest.testSharing DT_BFLOAT16The 1) disables the entire test. While 2) only filter some numeric typesso that they are not used in those tests.\n",
            "Your Model Prediction: DOCUMENTATION\n",
            "\n",
            "Comment: /** * @brief Manages memory allocation and synchronization between the host (CPU) * and device (GPU). * * TODO(dox): more thorough description. */\n",
            "Your Model Prediction: DOCUMENTATION\n",
            "\n",
            "Comment: TODO(nsilberman): Documentation.\n",
            "Your Model Prediction: DOCUMENTATION\n",
            "\n",
            "Comment: /*l*/) todo: add assertion }\n",
            "Your Model Prediction: IMPLEMENTATION\n",
            "\n",
            "Comment: TODO: add loading from checkpoint\n",
            "Your Model Prediction: IMPLEMENTATION\n",
            "\n",
            "Comment: TODO(satok): Implement all possible cases.\n",
            "Your Model Prediction: IMPLEMENTATION\n",
            "\n",
            "Comment: Buffers for constants are ignored unless the alloc_constants option is set. Also ignore buffers that we're not meant to assign. TODO(b/32248867): For consistency, constants should get allocations.\n",
            "Your Model Prediction: IMPLEMENTATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data for the table\n",
        "comments = [\n",
        "    \"Adjust learning per minibatches...\",\n",
        "    \"FIXME NEON has 16 quad registers...\",\n",
        "    \"We keep track of the pending count...\",\n",
        "    \"TODO: We should be able to move...\",\n",
        "    \"note: the temp variable here...\",\n",
        "    \"Hack for the tracer that allows...\",\n",
        "    \"TODO we could do this much...\",\n",
        "    \"#pragma omp parallel for...\",\n",
        "    \"Linux gcc barfs on this...\",\n",
        "    \"TODO: fix libname for OSX / Windows...\",\n",
        "    \"/* TODO: remove the extra copies...\",\n",
        "    \"/*TODO: merge with call site*/...\",\n",
        "    \"TODO vectorize mixed product\",\n",
        "    \"TODO: if p2p isn't supported...\",\n",
        "    \"TODO(b/73448937): Move all...\",\n",
        "    \"This really should be done in an...\",\n",
        "    \"ReshapeNode -- reshape input matrix...\",\n",
        "    \"TODO(xpan): Make it text proto...\",\n",
        "    \"/** * @brief Manages memory allocation...\",\n",
        "    \"TODO(nsilberman): Documentation.\",\n",
        "    \"/*l*/) todo: add assertion }\",\n",
        "    \"TODO: add loading from checkpoint\",\n",
        "    \"TODO(satok): Implement all...\",\n",
        "    \"Buffers for constants are ignored...\"\n",
        "]\n",
        "\n",
        "ground_truth = [\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\"\n",
        "]\n",
        "\n",
        "llm_prediction = [\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Compatibility Debt\",\n",
        "    \"Compatibility Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Test Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Requirement Debt\"\n",
        "]\n",
        "\n",
        "your_prediction = [\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Comment': comments,\n",
        "    'Ground Truth': ground_truth,\n",
        "    'LLM Prediction': llm_prediction,\n",
        "    'Your Prediction': your_prediction\n",
        "})\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2ZGWkzCGwePY",
        "outputId": "23d5a72f-5376-47b7-e496-a9e16d5cf719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Comment    Ground Truth  \\\n",
            "0          Adjust learning per minibatches...       ALGORITHM   \n",
            "1         FIXME NEON has 16 quad registers...       ALGORITHM   \n",
            "2       We keep track of the pending count...       ALGORITHM   \n",
            "3          TODO: We should be able to move...       ALGORITHM   \n",
            "4             note: the temp variable here...       ALGORITHM   \n",
            "5          Hack for the tracer that allows...       ALGORITHM   \n",
            "6               TODO we could do this much...       ALGORITHM   \n",
            "7                 #pragma omp parallel for...       ALGORITHM   \n",
            "8                  Linux gcc barfs on this...   COMPATIBILITY   \n",
            "9      TODO: fix libname for OSX / Windows...   COMPATIBILITY   \n",
            "10        /* TODO: remove the extra copies...          DESIGN   \n",
            "11          /*TODO: merge with call site*/...          DESIGN   \n",
            "12               TODO vectorize mixed product          DESIGN   \n",
            "13            TODO: if p2p isn't supported...          DESIGN   \n",
            "14              TODO(b/73448937): Move all...          DESIGN   \n",
            "15        This really should be done in an...          DESIGN   \n",
            "16     ReshapeNode -- reshape input matrix...          DESIGN   \n",
            "17          TODO(xpan): Make it text proto...   DOCUMENTATION   \n",
            "18  /** * @brief Manages memory allocation...   DOCUMENTATION   \n",
            "19           TODO(nsilberman): Documentation.   DOCUMENTATION   \n",
            "20               /*l*/) todo: add assertion }  IMPLEMENTATION   \n",
            "21          TODO: add loading from checkpoint  IMPLEMENTATION   \n",
            "22              TODO(satok): Implement all...  IMPLEMENTATION   \n",
            "23       Buffers for constants are ignored...  IMPLEMENTATION   \n",
            "\n",
            "        LLM Prediction Your Prediction  \n",
            "0       Algorithm Debt       ALGORITHM  \n",
            "1       Algorithm Debt       ALGORITHM  \n",
            "2       Algorithm Debt       ALGORITHM  \n",
            "3          Design Debt       ALGORITHM  \n",
            "4          Design Debt       ALGORITHM  \n",
            "5          Design Debt       ALGORITHM  \n",
            "6       Algorithm Debt       ALGORITHM  \n",
            "7       Algorithm Debt       ALGORITHM  \n",
            "8   Compatibility Debt   COMPATIBILITY  \n",
            "9   Compatibility Debt   COMPATIBILITY  \n",
            "10         Design Debt          DESIGN  \n",
            "11         Design Debt          DESIGN  \n",
            "12      Algorithm Debt  IMPLEMENTATION  \n",
            "13    Requirement Debt          DESIGN  \n",
            "14         Design Debt          DESIGN  \n",
            "15         Design Debt          DESIGN  \n",
            "16         Design Debt          DESIGN  \n",
            "17    Requirement Debt   DOCUMENTATION  \n",
            "18  Documentation Debt   DOCUMENTATION  \n",
            "19  Documentation Debt   DOCUMENTATION  \n",
            "20           Test Debt  IMPLEMENTATION  \n",
            "21    Requirement Debt  IMPLEMENTATION  \n",
            "22    Requirement Debt  IMPLEMENTATION  \n",
            "23    Requirement Debt  IMPLEMENTATION  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = [\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"ALGORITHM\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"COMPATIBILITY\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"DOCUMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\",\n",
        "    \"IMPLEMENTATION\"\n",
        "]\n",
        "\n",
        "llm_predictions = [\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Compatibility Debt\",\n",
        "    \"Compatibility Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Algorithm Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Design Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Test Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Requirement Debt\"\n",
        "]\n",
        "\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Comment\": llm_examples,\n",
        "    \"Ground Truth\": ground_truth,\n",
        "    \"LLM Prediction\": llm_predictions,\n",
        "    \"Your Model Prediction\": pred  # replace with your predictions variable if needed\n",
        "})\n",
        "\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87cua57MtzCx",
        "outputId": "f852271d-b9d3-469c-b804-bc12ae1f2507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Comment    Ground Truth  \\\n",
            "0   Adjust learning per minibatches at very beginn...       ALGORITHM   \n",
            "1   FIXME NEON has 16 quad registers, but since th...       ALGORITHM   \n",
            "2   We keep track of the pending count and dead in...       ALGORITHM   \n",
            "3   TODO: We should be able to move instead of cop...       ALGORITHM   \n",
            "4   note: the temp variable here gets completely e...       ALGORITHM   \n",
            "5   Hack for the tracer that allows us to represen...       ALGORITHM   \n",
            "6   TODO we could do this much more efficiently, w...       ALGORITHM   \n",
            "7   #pragma omp parallel for TODO: Depending in ci...       ALGORITHM   \n",
            "8   Linux gcc barfs on this ^^ for 'us = (double)(...   COMPATIBILITY   \n",
            "9   TODO: fix libname for OSX / WindowsTODO: just ...   COMPATIBILITY   \n",
            "10  /* TODO: remove the extra copies of the input....          DESIGN   \n",
            "11  /*TODO: merge with call site*/ void BackpropTo...          DESIGN   \n",
            "12                       TODO vectorize mixed product          DESIGN   \n",
            "13  TODO: if p2p isn't supported, this should beco...          DESIGN   \n",
            "14  TODO(b/73448937): Move all update damping code...          DESIGN   \n",
            "15  This really should be done in an external debu...          DESIGN   \n",
            "16  ==============================================...          DESIGN   \n",
            "17  TODO(xpan): Make it text proto if it doesn't s...   DOCUMENTATION   \n",
            "18  /** * @brief Manages memory allocation and syn...   DOCUMENTATION   \n",
            "19                   TODO(nsilberman): Documentation.   DOCUMENTATION   \n",
            "20                       /*l*/) todo: add assertion }  IMPLEMENTATION   \n",
            "21                  TODO: add loading from checkpoint  IMPLEMENTATION   \n",
            "22         TODO(satok): Implement all possible cases.  IMPLEMENTATION   \n",
            "23  Buffers for constants are ignored unless the a...  IMPLEMENTATION   \n",
            "\n",
            "        LLM Prediction Your Model Prediction  \n",
            "0       Algorithm Debt        IMPLEMENTATION  \n",
            "1       Algorithm Debt        IMPLEMENTATION  \n",
            "2       Algorithm Debt        IMPLEMENTATION  \n",
            "3          Design Debt        IMPLEMENTATION  \n",
            "4          Design Debt        IMPLEMENTATION  \n",
            "5          Design Debt        IMPLEMENTATION  \n",
            "6       Algorithm Debt        IMPLEMENTATION  \n",
            "7       Algorithm Debt        IMPLEMENTATION  \n",
            "8   Compatibility Debt        IMPLEMENTATION  \n",
            "9   Compatibility Debt        IMPLEMENTATION  \n",
            "10         Design Debt        IMPLEMENTATION  \n",
            "11         Design Debt        IMPLEMENTATION  \n",
            "12      Algorithm Debt        IMPLEMENTATION  \n",
            "13    Requirement Debt        IMPLEMENTATION  \n",
            "14         Design Debt        IMPLEMENTATION  \n",
            "15         Design Debt        IMPLEMENTATION  \n",
            "16         Design Debt        IMPLEMENTATION  \n",
            "17    Requirement Debt        IMPLEMENTATION  \n",
            "18  Documentation Debt        IMPLEMENTATION  \n",
            "19  Documentation Debt        IMPLEMENTATION  \n",
            "20           Test Debt        IMPLEMENTATION  \n",
            "21    Requirement Debt        IMPLEMENTATION  \n",
            "22    Requirement Debt        IMPLEMENTATION  \n",
            "23    Requirement Debt        IMPLEMENTATION  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Prepare the LLM Examples as a “Test Set”"
      ],
      "metadata": {
        "id": "pxln9nd7znfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example comments from LLM paper\n",
        "llm_examples = [\n",
        "    \"Either a tensor pointer (pass-by-reference) or a tensor (pass-by-value). TODO(yuanbyu): A better way to do has_value?\",\n",
        "    \"/*! \\\\brief path to the csv file */\",\n",
        "    \"Declare node, internal data structure.\",\n",
        "    \"TODO: actually, as long as the type is floating point, we can\",\n",
        "    \"Reorder Cast and Transpose if beneficial. A common pattern after the layout optimizer is casting an uint8 NHWC image to float before transposing it to NCHW.\"\n",
        "    # ... add the rest of the examples you want to compare\n",
        "]\n",
        "\n",
        "# Optional: convert to lowercase and strip whitespace, same as training\n",
        "llm_examples_clean = [c.lower().strip() for c in llm_examples]\n"
      ],
      "metadata": {
        "id": "7mibVluIzkDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Predict Using Your Trained Model"
      ],
      "metadata": {
        "id": "KxcF2jMOzu75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on LLM examples\n",
        "llm_predictions = best_model.predict(llm_examples_clean)\n",
        "\n",
        "# Print results\n",
        "for comment, pred in zip(llm_examples, llm_predictions):\n",
        "    print(f\"Comment: {comment}\\nYour Model Prediction: {pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1blJ8Hnzo2I",
        "outputId": "98895b4e-c33d-4f8a-bb32-4d8ae0bf1344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment: Either a tensor pointer (pass-by-reference) or a tensor (pass-by-value). TODO(yuanbyu): A better way to do has_value?\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: /*! \\brief path to the csv file */\n",
            "Your Model Prediction: WITHOUT_CLASSIFICATION\n",
            "\n",
            "Comment: Declare node, internal data structure.\n",
            "Your Model Prediction: WITHOUT_CLASSIFICATION\n",
            "\n",
            "Comment: TODO: actually, as long as the type is floating point, we can\n",
            "Your Model Prediction: DESIGN\n",
            "\n",
            "Comment: Reorder Cast and Transpose if beneficial. A common pattern after the layout optimizer is casting an uint8 NHWC image to float before transposing it to NCHW.\n",
            "Your Model Prediction: WITHOUT_CLASSIFICATION\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Comparison Table"
      ],
      "metadata": {
        "id": "1li-AAZez3ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ground_truth = [\n",
        "    \"DESIGN\",\n",
        "    \"WITHOUT_CLASSIFICATION\",\n",
        "    \"WITHOUT_CLASSIFICATION\",\n",
        "    \"DESIGN\",\n",
        "    \"DESIGN\"\n",
        "    # ... corresponding ground truths for each example\n",
        "]\n",
        "\n",
        "llm_predictions = [\n",
        "    \"Design Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Documentation Debt\",\n",
        "    \"Requirement Debt\",\n",
        "    \"Algorithm Debt\"\n",
        "    # ... corresponding LLM predictions\n",
        "]\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Comment\": llm_examples,\n",
        "    \"Ground Truth\": ground_truth,\n",
        "    \"LLM Prediction\": llm_predictions,\n",
        "    \"Your Model Prediction\": llm_predictions  # replace with your predictions variable if needed\n",
        "})\n",
        "\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqV83SONzyIR",
        "outputId": "a3a17521-82d2-41f9-8b99-17e4eedeebc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Comment            Ground Truth  \\\n",
            "0  Either a tensor pointer (pass-by-reference) or...                  DESIGN   \n",
            "1                 /*! \\brief path to the csv file */  WITHOUT_CLASSIFICATION   \n",
            "2             Declare node, internal data structure.  WITHOUT_CLASSIFICATION   \n",
            "3  TODO: actually, as long as the type is floatin...                  DESIGN   \n",
            "4  Reorder Cast and Transpose if beneficial. A co...                  DESIGN   \n",
            "\n",
            "       LLM Prediction Your Model Prediction  \n",
            "0         Design Debt           Design Debt  \n",
            "1  Documentation Debt    Documentation Debt  \n",
            "2  Documentation Debt    Documentation Debt  \n",
            "3    Requirement Debt      Requirement Debt  \n",
            "4      Algorithm Debt        Algorithm Debt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Accuracy"
      ],
      "metadata": {
        "id": "PSszeUQsz-Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Map text labels to the same format as your model (if needed)\n",
        "# e.g., your model uses 'DESIGN', 'DOCUMENTATION', etc.\n",
        "\n",
        "f1 = f1_score(ground_truth, llm_predictions, average='macro')\n",
        "acc = accuracy_score(ground_truth, llm_predictions)\n",
        "\n",
        "print(f\"F1 Score (Macro) on LLM Examples: {f1:.2f}\")\n",
        "print(f\"Accuracy on LLM Examples: {acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E78Ve1Lz84n",
        "outputId": "0fbd51e4-84e3-470e-e94b-a10a4d752efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Macro) on LLM Examples: 0.00\n",
            "Accuracy on LLM Examples: 0.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}